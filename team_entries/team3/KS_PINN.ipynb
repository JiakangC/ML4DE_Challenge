{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49bfc51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dab1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Class\n",
    "\n",
    "# Fully connected neural network with number of layers, neurons, input size, output size and activation function as parameters\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_layers, num_neurons, input_size, output_size, activation_function):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.activation_function = activation_function\n",
    "\n",
    "        # Input layer\n",
    "        self.layers.append(nn.Linear(input_size, num_neurons))\n",
    "\n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.layers.append(nn.Linear(num_neurons, num_neurons))\n",
    "\n",
    "        # Output layer\n",
    "        self.layers.append(nn.Linear(num_neurons, output_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = self.activation_function(layer(x))\n",
    "        x = self.layers[-1](x)\n",
    "        return x\n",
    "\n",
    "## define the activation functions: tanh() and sin()\n",
    "def tanh(x):\n",
    "    return torch.tanh(x)\n",
    "\n",
    "def sin(x):\n",
    "    return torch.sin(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7d71e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial condition \n",
    "def ic_func(x):\n",
    "    return np.cos(x[:, 0:1]) + 0.1 * np.sin(2 * x[:, 0:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5cc91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boundary condition\n",
    "\n",
    "## periodic boundary condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00717d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function construction\n",
    "\n",
    "## Residual loss function\n",
    "def Residual_NN(x, u, t, u_t, u_xx):\n",
    "    # Compute the residual of the PDE\n",
    "    f = u_t + u_xx - np.sin(t) * np.cos(x)\n",
    "    return f\n",
    "\n",
    "## Boundary loss function\n",
    "def Boundary_NN(x, t, u):\n",
    "    # Compute the boundary condition loss\n",
    "    u_bc = torch.zeros_like(u)\n",
    "    return u - u_bc\n",
    "\n",
    "## Initial loss function\n",
    "def Initial_NN(x, u):\n",
    "    # Compute the initial condition loss\n",
    "    u_ic = ic_func(x)\n",
    "    return u - u_ic\n",
    "\n",
    "## training loss function\n",
    "def train_loss(data, model):\n",
    "    x = x.requires_grad_()\n",
    "    t = t.requires_grad_()\n",
    "    u = u.requires_grad_()\n",
    "    u_t = u_t.requires_grad_()\n",
    "    u_xx = u_xx.requires_grad_()\n",
    "\n",
    "\n",
    "    # Compute the total loss\n",
    "    res_loss = Residual_NN(x, u, t, u_t, u_xx)\n",
    "    bc_loss = Boundary_NN(x, t, u)\n",
    "    ic_loss = Initial_NN(x, u)\n",
    "    total_loss = res_loss + bc_loss + ic_loss\n",
    "    return total_loss, res_loss,  ic_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df9dd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training process\n",
    "epochs = 5000\n",
    "\n",
    "loss_history = []\n",
    "ode_loss_history = []\n",
    "initial_loss_history = []\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "model = NeuralNetwork(num_layers=4, num_neurons=50, input_size=1, output_size=1, activation_function=tanh)\n",
    "print(model)\n",
    "\n",
    "x_train = torch.linspace(-2, 2, 100).view(-1, 1)  # Training points\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    total_loss, ode_loss, initial_loss = train_loss(model, x_train)\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    \n",
    "    loss_history.append(total_loss.item())\n",
    "    ode_loss_history.append(ode_loss.item())\n",
    "    initial_loss_history.append(initial_loss.item())\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {total_loss.item():.6f}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML4DE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
